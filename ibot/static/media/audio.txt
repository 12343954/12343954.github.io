大家好，欢迎来看我们的智能机器人！我们的理想是，用AI做点实事！
比如这个垃圾智能分拣机器人，采用全球最快的人工智能技术YOLO v3来做物体识别。准确性高达98%，甚至99.8%，以及高达30fps处理能力。性能比google的tensorflow 2快3倍。
大致原理是，采集少量样本，标注后，训练AI。再采用眼在手外(eye-to-hand)模式，高空安装工业摄像机获取车间作业面上物体摆放视图，传至AI大脑辨识，识别物体的类别、精度、大小、角度、位置、中心点等关键信息，然后转成机械手坐标系，再制作成机械手的运动计划，使之智能分拣。
具体流程如下：

第一步，安装高空工业摄像头(眼睛部分)
实时监控车间工作面上的物体传输
采用无畸变高清摄像头
并且标定校准成像
确保图像清晰稳定
物体通过振动筛、风选、水选等设备
优先过滤泥土、粉尘、水渍、漂浮物等
剩余固体打散到传送带上
运输至作业车间
以供AI辨识筛检

第二部，作业面图像截取
也叫鸟瞰图生成
使用机器视觉Opencv图像处理技术
通过4个标定点
截取做页面
生成“鸟瞰图”
通过无畸变矫正
确保物体正确分布在作业面上
为后续AI辨识准确位置
提供技术保障


三：为什么生成鸟瞰图？由于摄像头是仿照视网膜成像原理，摄像机斜视拍摄一物体后，形成的图像远离中心点会发生弯曲变形，会造成图像与实际位置形状不符，为了消除这种弯曲变形从而获得图像的真实位置形状，使远方也呈现直线，我们必须做摄像头标定，使图像呈现在大地水平面上，这种称之为“重投影”。最终达到使图像呈现的是正好摄像头在正上方的位置的效果，就是所谓“鸟瞰图”。


第四步：物体检测，这是YOLO自身功能。开源，少量样本(每个样本20张)，短时间内就可训练出强大的AI大脑，准确度高达98%，这是YOLO的过人之处，比Tensorflow更高的性能，以及更低的资源占用率，使全球各大公司都在使用，甚至多国军方开发致命武器，导致YOLO作者5年前放弃开发。目前YOLO v4，被台湾做了些许改动，也只一些周边功能的升级，未涉及到核心模型改动，但它依旧很强大，而且越来越强大！


第五步：角度位置识别，在物体识别基础上，我们再次加入了机器视觉技术，让AI辨识出更多维度数据，比如物体大小、位置、角度、中心点等等。这些维度将被运用在机械手抓取的工作上。目前只是python下实现了功能，未来我们会在C++层面实现，这样识别速度更快。一切都是为了效率！




第六步：AI服务器，是这样的。硬件上，我们只是采购了中低端显卡Nvida RTX 2060 6GB显存，CPU i7-9700，以及32GB内存，都能跑出如此优异的成绩，30fps！如果采用更高配置的泰坦系列、特斯拉系列显卡集群，一切应该快如闪电！软件上，我们也在想尽一切办法优化算法，这一点也需要更多能人志士的加入，来一起做大做强！


7，平均损失曲线。这是10种样本，一共200张图片，在训练8-10小时，不到2.5万步下，avg-loss就降到0.5以下。YOLO如此强大，加上我们自研的训练脚本，新增更多样本训练，也轻松自如。如果样本更精细、硬件更高配的情况下，AI辨识度会更高更快。


第八步：运动计划，前面软件部分识别出的多维数据，最终都会汇聚到运动计划。怎样规划硬件机械手臂以最优路径、最短时间、最高质量的完成智能分拣，是考验运动计划是否强大之所在。硬件arduino物联网的世界也非常精彩，所幸我们也有好多共同理想者，都在为彼此奋斗中！

第九步：最后，智能分拣，我们终于做出来了。马上，我们将从实验室走向生产车间，我们会用KUKA机械手等大型设备，一个车间我们会一排3个手，甚至两排6个手，协同作业。从长期投入来看，智能生产线成本一定会比人工成本更低、更有效率，而且24小时不间断工作。
德国Zen Robotic就是我们的下一个目标，我们坚信一定能从成本和效率上，超越他们的龙门机械手。
研发过程历经8、9个月的日夜兼程，填过无数的坑，没有一分收入，没有一丝怨言，只因我们只想用AI干点实事，真正造福于人类，让人们从低端、危险、枯燥乏味的劳动中解放出来。这也将是我们永远的理想！
非常感谢看完我们的介绍，希望能遇到更多志趣相投的能人志士加入我们，我们有好多想做的事，好多idea需要实现，我们更擅长，把理想，变现！







